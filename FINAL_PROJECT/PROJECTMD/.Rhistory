#divide between test and train
individual_person_test<-individual_person[1:(nrow(individual_person)/2),]
individual_person_train<-individual_person[(nrow(individual_person)/2+1):(nrow(individual_person)),]
individual_prediction<-knn(train = individual_person_train[,-1], test = individual_person_test[,-1],
cl = individual_person_train[,1], k = var_k[i])
confusion <- confusionMatrix(individual_prediction, individual_person_test[,1])
vark_results[i,j] <- confusion$overall['Accuracy']
}
}
#printing results ordered by accuracy
print(vark_results)
vark_results<-rowMeans(vark_results, na.rm = FALSE, dims = 1)
qplot(unlist(1:length(vark_results)),unlist(vark_results), geom = "line",xlab="Increasing values for the parameter k",ylab="Accuracy (in percentace)") + ggtitle("Accuracy for increasing number of principal components")
var_k <-c(1, 5, 10, 15, 20, 30, 40, 50, 100, 150)
vark_results<-matrix(nrow = length(var_k), ncol = length(person_index)-1)
for(i in 1:length(var_k)){
for(j in 1:length){
lower<-person_index[j]+1 #calculate person raw range - this is the lower range bound
#for the number of persons split 50 - 50 between training and test set
#save one person per time in individual person
individual_person<-single_person[lower:person_index[j+1],1:i]
#shaffle data of the person
individual_person<-individual_person[sample(nrow(individual_person)),]
#divide between test and train
individual_person_test<-individual_person[1:(nrow(individual_person)/2),]
individual_person_train<-individual_person[(nrow(individual_person)/2+1):(nrow(individual_person)),]
individual_prediction<-knn(train = individual_person_train[,-1], test = individual_person_test[,-1],
cl = individual_person_train[,1], k = var_k[i])
confusion <- confusionMatrix(individual_prediction, individual_person_test[,1])
vark_results[i,j] <- confusion$overall['Accuracy']
}
}
#printing results ordered by accuracy
print(vark_results)
source('~/Desktop/ML/Machine_Learning/PROJECTMD/knn.R')
source('~/Desktop/ML/Machine_Learning/PROJECTMD/person_dependent.R')
source('~/Desktop/ML/Machine_Learning/PROJECTMD/person_dependent.R')
source('~/Desktop/ML/Machine_Learning/PROJECTMD/person_dependent.R')
round(length(dataset/100)*10)
length(dataset)
length(dataset[,1])
round(length(dataset[,1]/100)*10)
round(length(dataset[,1])/100*10)
create_pca_dataset<-function(){
pers_dep_pca<-prcomp(dataset[2:length(dataset[1,])], retx=TRUE, center=TRUE, scale=TRUE)
pers_dep_data<-pers_dep_pca$x[,1:ncol(dataset)-1] #pca object
pers_dep_label<-dataset[,1] #labels from the original dataset
#bind the pca components with labels
pers_dep<-matrix(nrow = length(dataset[,1]), ncol = ncol(dataset))
#conevrting large matrix into data frame matrix - indexing reasoning
pers_dep <- as.data.frame(matrix(unlist(pers_dep), nrow = length(dataset[,1])))
pers_dep[,1]<-pers_dep_label
pers_dep[,-1]<-pers_dep_data
return(pers_dep)
}
pers_dep<-create_pca_dataset()
pers_dep
View(pers_dep)
View(pers_dep)
#insert the necessary dataset
cross_val<-function(pers_dep){
cross_val_results<-vector(nrow = 1,ncol=runs)
runs=2
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs-1){
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
pers_dep_train<-pers_dep[-(i:i+1),]
pers_dep_test<-pers_dep[i:i+1,]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i] <- confusion$overall['Accuracy']
}
return(cross_val_results)
}
cross_val<-create_pca_dataset(dataset[,3])
cross_val<-create_pca_dataset(dataset)
rm(list=ls())
source('/Users/elisabetta/Desktop/ML/Machine_Learning/PROJECTMD/load_dataset.R')
create_pca_dataset<-function(dataset){
pers_dep_pca<-prcomp(dataset[2:length(dataset[1,])], retx=TRUE, center=TRUE, scale=TRUE)
pers_dep_data<-pers_dep_pca$x[,1:ncol(dataset)-1] #pca object
pers_dep_label<-dataset[,1] #labels from the original dataset
#bind the pca components with labels
pers_dep<-matrix(nrow = length(dataset[,1]), ncol = ncol(dataset))
#conevrting large matrix into data frame matrix - indexing reasoning
pers_dep <- as.data.frame(matrix(unlist(pers_dep), nrow = length(dataset[,1])))
pers_dep[,1]<-pers_dep_label
pers_dep[,-1]<-pers_dep_data
return(pers_dep)
}
pers_dep<-create_pca_dataset(dataset)
cross_val<-create_pca_dataset(dataset)
cross_val
cross_val_result<-cross_val(create_pca_dataset(dataset[3,4]))
cross_val<-function(pers_dep){
cross_val_results<-vector(nrow = 1,ncol=runs)
runs=2
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs-1){
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
pers_dep_train<-pers_dep[-(i:i+1),]
pers_dep_test<-pers_dep[i:i+1,]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i] <- confusion$overall['Accuracy']
}
return(cross_val_results)
}
cross_val_result<-cross_val(create_pca_dataset(dataset[3,4]))
pca<-create_pca_dataset(dataset)
pca<-pca[3,4]
cross_val_result<-cross_val(pca)
cross_val<-function(pers_dep){
cross_val_results<-matrix(nrow = 1,ncol=runs)
runs=2
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs-1){
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
pers_dep_train<-pers_dep[-(i:i+1),]
pers_dep_test<-pers_dep[i:i+1,]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i] <- confusion$overall['Accuracy']
}
return(cross_val_results)
}
cross_val_result<-cross_val(pca)
cross_val<-function(pers_dep){
runs=2
cross_val_results<-matrix(nrow = 1,ncol=runs)
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs-1){
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
pers_dep_train<-pers_dep[-(i:i+1),]
pers_dep_test<-pers_dep[i:i+1,]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i] <- confusion$overall['Accuracy']
}
return(cross_val_results)
}
cross_val_result<-cross_val(pca)
nrow(pers_dep)
nrow(pca)
pca<-create_pca_dataset(dataset)
pca<-pca[3,4]
cross_val_result<-cross_val(pca)
#insert the necessary dataset
cross_val<-function(pers_dep){
runs=2
cross_val_results<-matrix(nrow = 1,ncol=runs)
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs-1){
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
pers_dep_train<-pers_dep[-(i:i+1),]
pers_dep_test<-pers_dep[i:i+1,]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i] <- confusion$overall['Accuracy']
}
return(cross_val_results)
}
#create dataset with PCAs
pca<-create_pca_dataset(dataset)
pca<-pca[1:3,1:4]
cross_val_result<-cross_val(pca)
#insert the necessary dataset
cross_val<-function(pers_dep){
runs=2
cross_val_results<-matrix(nrow = 1,ncol=runs)
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs-1){
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
pers_dep_train<-pers_dep[-(i:i+1),]
pers_dep_test<-pers_dep[i:i+1,]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i] <- confusion$overall['Accuracy']
}
return(cross_val_results)
}
#create dataset with PCAs
pca<-create_pca_dataset(dataset)
cross_val_result<-cross_val(pca)
View(pca)
View(pca)
#insert the necessary dataset
cross_val<-function(pers_dep){
runs=2
cross_val_results<-matrix(nrow = 1,ncol=runs)
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs-1){
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
pers_dep_train<-pers_dep[-(fold_index[i]:fold_index[i+1]),]
pers_dep_test<-pers_dep[fold_index[i]:fold_index[i+1],]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i] <- confusion$overall['Accuracy']
}
return(cross_val_results)
}
#create dataset with PCAs
pca<-create_pca_dataset(dataset)
cross_val_result<-cross_val(pca)
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#cr
fold_index[3+1]
fold_index[i]:fold_index[i + 1]
cross_val_results<-matrix(nrow = 1,ncol=(runs+1))
runs=2
cross_val_results<-matrix(nrow = 1,ncol=(runs+1))
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
#insert the necessary dataset
cross_val<-function(pers_dep){
runs=2 #9
cross_val_results<-matrix(nrow = 1,ncol=(runs+1))
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs){
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
pers_dep_train<-pers_dep[-(fold_index[i]:fold_index[i+1]),]
pers_dep_test<-pers_dep[fold_index[i]:fold_index[i+1],]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i] <- confusion$overall['Accuracy']
}
return(cross_val_results)
}
#create dataset with PCAs
pca<-create_pca_dataset(dataset)
cross_val_result<-cross_val(pca)
cross_val_result
#insert the necessary dataset, cross validation for pca
cross_val_pca<-function(pers_dep){
runs=2
cross_val_results<-matrix(nrow = 1,ncol=runs)
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs){
for(j in 3:ncol(dataset)){
pers_dep<-pers_dep[sample(nrow(pers_dep)),1:j]
pers_dep_train<-pers_dep[-(fold_index[i]:fold_index[i+1]),]
pers_dep_test<-pers_dep[fold_index[i]:fold_index[i+1],]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i,j] <- confusion$overall['Accuracy']
}
}
return(cross_val_results)
}
#create dataset with PCAs
pca<-create_pca_dataset(dataset)
cross_val_result<-cross_val(pca)
View(cross_val_result)
View(cross_val_result)
View(cross_val_results)
View(cross_val_results)
#insert the necessary dataset, cross validation for pca
cross_val_pca<-function(pers_dep){
runs=2
cross_val_results<-matrix(nrow = runs,ncol=length(pers_dep))
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs){
for(j in 3:ncol(dataset)){
pers_dep<-pers_dep[sample(nrow(pers_dep)),1:j]
pers_dep_train<-pers_dep[-(fold_index[i]:fold_index[i+1]),]
pers_dep_test<-pers_dep[fold_index[i]:fold_index[i+1],]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i,j] <- confusion$overall['Accuracy']
}
}
return(cross_val_results)
}
#create dataset with PCAs
pca<-create_pca_dataset(dataset)
cross_val_result<-cross_val(pca)
cross_val_results<-matrix(nrow = runs,ncol=length(pers_dep))
cross_val_pca<-function(pers_dep){
runs=2
cross_val_results<-matrix(nrow = runs,ncol=length(pers_dep))
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs){
for(j in 3:ncol(dataset)){
pers_dep<-pers_dep[sample(nrow(pers_dep)),1:j]
pers_dep_train<-pers_dep[-(fold_index[i]:fold_index[i+1]),]
pers_dep_test<-pers_dep[fold_index[i]:fold_index[i+1],]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i,j] <- confusion$overall['Accuracy']
}
}
return(cross_val_results)
}
#create dataset with PCAs
pca<-create_pca_dataset(dataset)
cross_val_result<-cross_val(pca)
remove(cross_val_result)
cross_val_results[i,j] <- confusion$overall['Accuracy']
runs=2
cross_val_results<-matrix(nrow = runs,ncol=length(pers_dep))
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs){
for(j in 3:ncol(dataset)){
pers_dep<-pers_dep[sample(nrow(pers_dep)),1:j]
pers_dep_train<-pers_dep[-(fold_index[i]:fold_index[i+1]),]
pers_dep_test<-pers_dep[fold_index[i]:fold_index[i+1],]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i,j] <- confusion$overall['Accuracy']
}
}
cross_val_pca<-function(pers_dep){
runs=2
cross_val_results<-matrix(nrow = runs,ncol=length(pers_dep))
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs){
for(j in 3:ncol(dataset)){
pers_dep<-pers_dep[sample(nrow(pers_dep)),1:j]
pers_dep_train<-pers_dep[-(fold_index[i]:fold_index[i+1]),]
pers_dep_test<-pers_dep[fold_index[i]:fold_index[i+1],]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i,j] <- confusion$overall['Accuracy']
}
}
return(cross_val_results)
}
pca<-create_pca_dataset(dataset)
View(pca)
View(pca)
cross_val_result<-cross_val(pca)
View(cross_val_results)
View(cross_val_results)
rm(list=ls())
source('/Users/elisabetta/Desktop/ML/Machine_Learning/PROJECTMD/load_dataset.R')
#insert the necessary dataset, cross validation for pca
cross_val_pca<-function(pers_dep){
runs=9
cross_val_results<-matrix(nrow = runs,ncol=length(pers_dep))
fold_index<-seq(0, length(dataset[,1]),round(length(dataset[,1])/100*10))#create chunk of 10% per time
for(i in 1:runs){
for(j in 3:ncol(dataset)){
pers_dep<-pers_dep[sample(nrow(pers_dep)),1:j]
pers_dep_train<-pers_dep[-(fold_index[i]:fold_index[i+1]),]
pers_dep_test<-pers_dep[fold_index[i]:fold_index[i+1],]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
cross_val_results[i,j] <- confusion$overall['Accuracy']
}
}
return(cross_val_results)
}
#create dataset with PCAs
pca<-create_pca_dataset(dataset)
cross_val_result<-cross_val(pca)
source('~/Desktop/ML/Machine_Learning/PROJECTMD/person_dependent.R')
source('~/Desktop/ML/Machine_Learning/PROJECTMD/person_dependent.R')
pca<-create_pca_dataset(dataset)
View(pca)
View(pca)
person_dep_function<-function(dataset){
pers_dep<-create_pca_dataset(dataset)
train_sample_num<-round((nrow(dataset)/100)*50)
test_sample_num<-round((nrow(dataset)/100)*50)
#eliminate the last index from the range to use the right number of people
#create a sequence to access data one person per time
pca_results<-matrix(nrow = length(dataset)-3) #results using 11 PCAs
person_dep_function<-function(dataset){
pers_dep<-create_pca_dataset(dataset)
train_sample_num<-round((nrow(dataset)/100)*50)
test_sample_num<-round((nrow(dataset)/100)*50)
#eliminate the last index from the range to use the right number of people
#create a sequence to access data one person per time
pca_results<-matrix(nrow = length(dataset)-3) #results using 11 PCAs
#########################run for an increasing number of PCAs with a split 70-30#####################
for(i in ncol(dataset)){
#shaffle data of the person
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
#take a certain number of principal component
pers_dep_dataset<-pers_dep[,1:i]
#divide between test and train
pers_dep_train<-pers_dep[1:(nrow(pers_dep_dataset)/2),]
pers_dep_test<-pers_dep[(nrow(pers_dep_dataset)/2+1):(nrow(pers_dep_dataset)),]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
pca_results[i] <- confusion$overall['Accuracy']
}
return(pca_results)
}
}
accuracies<-person_dep_function(dataset)
accuracies()
#run pca
person_dep_function<-function(dataset){
pers_dep<-create_pca_dataset(dataset)
train_sample_num<-round((nrow(dataset)/100)*50)
test_sample_num<-round((nrow(dataset)/100)*50)
#eliminate the last index from the range to use the right number of people
#create a sequence to access data one person per time
pca_results<-matrix(nrow = length(dataset)-3) #results using 11 PCAs
#########################run for an increasing number of PCAs with a split 70-30#####################
for(i in ncol(dataset)){
#shaffle data of the person
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
#take a certain number of principal component
pers_dep_dataset<-pers_dep[,1:i]
#divide between test and train
pers_dep_train<-pers_dep[1:(nrow(pers_dep_dataset)/2),]
pers_dep_test<-pers_dep[(nrow(pers_dep_dataset)/2+1):(nrow(pers_dep_dataset)),]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
pca_results[i] <- confusion$overall['Accuracy']
}
return(pca_results)
}
#printing results ordered by accuracy
#print(pca_results)
#result<-rowMeans(knn_results, na.rm = FALSE, dims = 1)
#qplot(unlist(1:length(pca_results)),unlist(pca_results), geom = "line",xlab="Number of principal components",ylab="Accuracy (in percentace)") + ggtitle("Accuracy for increasing number of principal components")
#max_pca_number<-which.max(pca_results)
accuracies<-person_dep_function()
#run pca
person_dep_function<-function(){
pers_dep<-create_pca_dataset(dataset)
train_sample_num<-round((nrow(dataset)/100)*50)
test_sample_num<-round((nrow(dataset)/100)*50)
#eliminate the last index from the range to use the right number of people
#create a sequence to access data one person per time
pca_results<-matrix(nrow = length(dataset)-3) #results using 11 PCAs
#########################run for an increasing number of PCAs with a split 70-30#####################
for(i in ncol(dataset)){
#shaffle data of the person
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
#take a certain number of principal component
pers_dep_dataset<-pers_dep[,1:i]
#divide between test and train
pers_dep_train<-pers_dep[1:(nrow(pers_dep_dataset)/2),]
pers_dep_test<-pers_dep[(nrow(pers_dep_dataset)/2+1):(nrow(pers_dep_dataset)),]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
pca_results[i] <- confusion$overall['Accuracy']
}
return(pca_results)
}
accuracies<-person_dep_function()
accuracies
i
#data from all the person with a training set that includes data from all persons
require(gmodels)
require(caret)
require(class)
#source('/Users/elisabetta/Desktop/ML/Machine_Learning/PROJECTMD/load_dataset.R')
source('C:/Users/Christian Arentsen/Git/Machine_Learning/FINAL_PROJECT/PROJECTMD/load_dataset.R')
########################PCA##############################################################
#function that returns a dataset containing just PCA
create_pca_dataset<-function(dataset){
pers_dep_pca<-prcomp(dataset[2:length(dataset[1,])], retx=TRUE, center=TRUE, scale=TRUE)
pers_dep_data<-pers_dep_pca$x[,1:ncol(dataset)-1] #pca object
pers_dep_label<-dataset[,1] #labels from the original dataset
#bind the pca components with labels
pers_dep<-matrix(nrow = length(dataset[,1]), ncol = ncol(dataset))
#conevrting large matrix into data frame matrix - indexing reasoning
pers_dep <- as.data.frame(matrix(unlist(pers_dep), nrow = length(dataset[,1])))
pers_dep[,1]<-pers_dep_label
pers_dep[,-1]<-pers_dep_data
return(pers_dep)
}
################################## RUN PCA #################################################
person_dep_function<-function(dataset){
pers_dep<-create_pca_dataset(dataset)
train_sample_num<-round((nrow(dataset)/100)*50)
test_sample_num<-round((nrow(dataset)/100)*50)
#eliminate the last index from the range to use the right number of people
#create a sequence to access data one person per time
pca_results<-matrix(nrow = length(dataset)) #results using 11 PCAs
#run for an increasing number of PCAs with a split 70-30#####################
for(i in 3:ncol(dataset)){
#shaffle data of the person
pers_dep<-pers_dep[sample(nrow(pers_dep)),]
#take a certain number of principal component
pers_dep_dataset<-pers_dep[,1:i]
#divide between test and train
pers_dep_train<-pers_dep[1:(nrow(pers_dep_dataset)/2),]
pers_dep_test<-pers_dep[(nrow(pers_dep_dataset)/2+1):(nrow(pers_dep_dataset)),]
pers_dep_prediction<-knn(train = pers_dep_train[,-1], test = pers_dep_test[,-1],
cl = pers_dep_train[,1], k = 1)
confusion <- confusionMatrix(pers_dep_prediction, pers_dep_test[,1])
pca_results[i] <- confusion$overall['Accuracy']
}
return(pca_results)
}
#printing results ordered by accuracy
#print(pca_results)
#result<-rowMeans(knn_results, na.rm = FALSE, dims = 1)
#qplot(unlist(1:length(pca_results)),unlist(pca_results), geom = "line",xlab="Number of principal components",ylab="Accuracy (in percentace)") + ggtitle("Accuracy for increasing number of principal components")
#max_pca_number<-which.max(pca_results)
accuracies<-person_dep_function(dataset)
